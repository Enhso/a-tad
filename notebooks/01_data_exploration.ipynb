{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0000001",
   "metadata": {},
   "source": [
    "# 01 -- Data Quality Report\n",
    "\n",
    "This notebook provides a comprehensive data-quality assessment of the\n",
    "extracted feature matrix produced by the Tactical State Discovery Engine.\n",
    "\n",
    "**Sections:**\n",
    "1. Data loading and overview\n",
    "2. Null-rate analysis (per column, per tier, per segment type)\n",
    "3. Feature distributions\n",
    "4. Correlation matrix\n",
    "5. Per-team summary statistics\n",
    "6. Outlier analysis\n",
    "7. Temporal coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=0.9)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "FEATURES_PATH = PROJECT_ROOT / \"data\" / \"output\" / \"features.parquet\"\n",
    "\n",
    "METADATA_COLS: set[str] = {\n",
    "    \"match_id\",\n",
    "    \"team_id\",\n",
    "    \"segment_type\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "    \"period\",\n",
    "    \"match_minute\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000003",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading & Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURES_PATH.exists():\n",
    "    df = pl.read_parquet(FEATURES_PATH)\n",
    "    print(f\"Loaded {FEATURES_PATH}\")\n",
    "else:\n",
    "    print(\n",
    "        f\"{FEATURES_PATH} not found.\\n\"\n",
    "        \"Run `python scripts/run_feature_extraction.py` first.\"\n",
    "    )\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols: list[str] = [\n",
    "    c for c in df.columns if c not in METADATA_COLS\n",
    "]\n",
    "tier_map: dict[str, str] = {}\n",
    "for col in feature_cols:\n",
    "    if col.startswith(\"t1_\"):\n",
    "        tier_map[col] = \"Tier 1\"\n",
    "    elif col.startswith(\"t2_\"):\n",
    "        tier_map[col] = \"Tier 2\"\n",
    "    elif col.startswith(\"t3_\"):\n",
    "        tier_map[col] = \"Tier 3\"\n",
    "    else:\n",
    "        tier_map[col] = \"Unknown\"\n",
    "\n",
    "print(f\"Rows              : {df.height:,}\")\n",
    "print(f\"Total columns     : {df.width}\")\n",
    "print(f\"Metadata columns  : {len(METADATA_COLS & set(df.columns))}\")\n",
    "print(f\"Feature columns   : {len(feature_cols)}\")\n",
    "\n",
    "tier_counts = (\n",
    "    pl.DataFrame({\"feature\": list(tier_map.keys()), \"tier\": list(tier_map.values())})\n",
    "    .group_by(\"tier\")\n",
    "    .agg(pl.col(\"feature\").count().alias(\"n_features\"))\n",
    "    .sort(\"tier\")\n",
    ")\n",
    "print(\"\\nFeatures per tier:\")\n",
    "print(tier_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_counts = (\n",
    "    df.group_by(\"segment_type\")\n",
    "    .agg(pl.len().alias(\"n_rows\"))\n",
    "    .sort(\"segment_type\")\n",
    ")\n",
    "print(\"Rows per segment type:\")\n",
    "print(segment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_matches = df[\"match_id\"].n_unique()\n",
    "n_teams = df[\"team_id\"].n_unique()\n",
    "periods = sorted(df[\"period\"].unique().to_list())\n",
    "\n",
    "print(f\"Unique matches : {n_matches}\")\n",
    "print(f\"Unique teams   : {n_teams}\")\n",
    "print(f\"Periods        : {periods}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000008",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Null-Rate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rates: dict[str, float] = {}\n",
    "for col in feature_cols:\n",
    "    null_rates[col] = df[col].null_count() / df.height if df.height > 0 else 0.0\n",
    "\n",
    "null_df = (\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"feature\": list(null_rates.keys()),\n",
    "            \"null_rate\": list(null_rates.values()),\n",
    "        }\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"feature\")\n",
    "        .map_elements(\n",
    "            lambda f: tier_map.get(f, \"Unknown\"),\n",
    "            return_dtype=pl.Utf8,\n",
    "        )\n",
    "        .alias(\"tier\")\n",
    "    )\n",
    "    .sort(\"null_rate\", descending=True)\n",
    ")\n",
    "\n",
    "cols_with_nulls = null_df.filter(pl.col(\"null_rate\") > 0.0)\n",
    "cols_no_nulls = null_df.filter(pl.col(\"null_rate\") == 0.0).height\n",
    "\n",
    "total_cells = df.height * len(feature_cols)\n",
    "total_nulls = sum(df[c].null_count() for c in feature_cols)\n",
    "overall_pct = 100.0 * total_nulls / total_cells if total_cells > 0 else 0.0\n",
    "\n",
    "print(f\"Overall null rate: {overall_pct:.2f}% ({total_nulls:,} / {total_cells:,})\")\n",
    "print(f\"Fully populated columns: {cols_no_nulls} / {len(feature_cols)}\")\n",
    "\n",
    "if cols_with_nulls.height > 0:\n",
    "    print(\"\\nColumns with nulls (descending):\")\n",
    "    print(cols_with_nulls.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null rate by tier\n",
    "tier_null = (\n",
    "    null_df.group_by(\"tier\")\n",
    "    .agg(\n",
    "        pl.col(\"null_rate\").mean().alias(\"mean_null_rate\"),\n",
    "        pl.col(\"null_rate\").max().alias(\"max_null_rate\"),\n",
    "        pl.col(\"null_rate\").filter(pl.col(\"null_rate\") > 0).count().alias(\"n_cols_with_nulls\"),\n",
    "        pl.col(\"feature\").count().alias(\"n_cols\"),\n",
    "    )\n",
    "    .sort(\"tier\")\n",
    ")\n",
    "print(\"Null rate summary by tier:\")\n",
    "print(tier_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise null rates for columns that have any nulls\n",
    "if cols_with_nulls.height > 0:\n",
    "    plot_df = cols_with_nulls.head(40)  # cap for readability\n",
    "    names = plot_df[\"feature\"].to_list()\n",
    "    rates = plot_df[\"null_rate\"].to_list()\n",
    "    tiers = plot_df[\"tier\"].to_list()\n",
    "\n",
    "    tier_palette = {\"Tier 1\": \"#4c72b0\", \"Tier 2\": \"#dd8452\", \"Tier 3\": \"#55a868\", \"Unknown\": \"#999999\"}\n",
    "    bar_colors = [tier_palette.get(t, \"#999999\") for t in tiers]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, len(names) * 0.28)))\n",
    "    y_pos = np.arange(len(names))\n",
    "    ax.barh(y_pos, [r * 100 for r in rates], color=bar_colors, edgecolor=\"white\", linewidth=0.5)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(names, fontsize=7)\n",
    "    ax.set_xlabel(\"Null rate (%)\")\n",
    "    ax.set_title(\"Null Rate per Feature Column (top 40)\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    handles = [Patch(facecolor=c, label=t) for t, c in tier_palette.items() if t in set(tiers)]\n",
    "    ax.legend(handles=handles, loc=\"lower right\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No columns have null values -- nothing to plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null rates by segment type\n",
    "for seg_type in df[\"segment_type\"].unique().sort().to_list():\n",
    "    seg = df.filter(pl.col(\"segment_type\") == seg_type)\n",
    "    seg_nulls = sum(seg[c].null_count() for c in feature_cols)\n",
    "    seg_cells = seg.height * len(feature_cols)\n",
    "    seg_pct = 100.0 * seg_nulls / seg_cells if seg_cells > 0 else 0.0\n",
    "    print(f\"  {seg_type:<12s}  null rate = {seg_pct:.2f}%  (rows={seg.height:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000013",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for all numeric feature columns\n",
    "desc = df.select(feature_cols).describe()\n",
    "print(desc.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select representative features (one per extractor group) for histograms\n",
    "_REPRESENTATIVE_PREFIXES = [\n",
    "    \"t1_spatial_event_centroid_x\",\n",
    "    \"t1_temporal_event_rate\",\n",
    "    \"t1_pass_count\",\n",
    "    \"t1_pass_completion_rate\",\n",
    "    \"t1_carry_count\",\n",
    "    \"t1_defend_pressure_count\",\n",
    "    \"t1_shoot_count\",\n",
    "    \"t1_context_score_differential\",\n",
    "    \"t1_context_possession_share\",\n",
    "    \"t2_shape_engagement_line\",\n",
    "    \"t2_press_intensity\",\n",
    "    \"t2_press_ppda\",\n",
    "    \"t2_transition_transition_speed\",\n",
    "    \"t2_zonal_box_entries\",\n",
    "    \"t3_formation_team_centroid_x\",\n",
    "    \"t3_relational_avg_nearest_opponent_dist\",\n",
    "]\n",
    "\n",
    "plot_features = [f for f in _REPRESENTATIVE_PREFIXES if f in feature_cols]\n",
    "\n",
    "n_plots = len(plot_features)\n",
    "n_cols_grid = 4\n",
    "n_rows_grid = (n_plots + n_cols_grid - 1) // n_cols_grid\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows_grid, n_cols_grid,\n",
    "    figsize=(n_cols_grid * 3.2, n_rows_grid * 2.8),\n",
    ")\n",
    "axes_flat = axes.flatten() if n_plots > 1 else [axes]\n",
    "\n",
    "for idx, feat in enumerate(tqdm(plot_features, desc=\"Plotting histograms\")):\n",
    "    ax = axes_flat[idx]\n",
    "    vals = df[feat].drop_nulls().to_numpy()\n",
    "    if len(vals) == 0:\n",
    "        ax.set_title(feat, fontsize=7)\n",
    "        ax.text(0.5, 0.5, \"all null\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        continue\n",
    "    ax.hist(vals, bins=50, color=\"#4c72b0\", edgecolor=\"white\", linewidth=0.3)\n",
    "    ax.set_title(feat.replace(\"t1_\", \"\").replace(\"t2_\", \"\").replace(\"t3_\", \"\"), fontsize=7)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "# Hide unused axes\n",
    "for idx in range(n_plots, len(axes_flat)):\n",
    "    axes_flat[idx].set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Feature Distributions (representative sample)\", fontsize=11, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison: window vs possession segments\n",
    "_COMPARE_FEATURES = [\n",
    "    \"t1_pass_count\",\n",
    "    \"t1_temporal_event_rate\",\n",
    "    \"t1_spatial_event_centroid_x\",\n",
    "    \"t1_defend_pressure_count\",\n",
    "]\n",
    "compare_features = [f for f in _COMPARE_FEATURES if f in feature_cols]\n",
    "\n",
    "if compare_features:\n",
    "    fig, axes = plt.subplots(1, len(compare_features), figsize=(len(compare_features) * 3.5, 3))\n",
    "    if len(compare_features) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, feat in zip(axes, compare_features):\n",
    "        for seg_type, color in [(\"window\", \"#4c72b0\"), (\"possession\", \"#dd8452\")]:\n",
    "            vals = (\n",
    "                df.filter(pl.col(\"segment_type\") == seg_type)[feat]\n",
    "                .drop_nulls()\n",
    "                .to_numpy()\n",
    "            )\n",
    "            if len(vals) > 0:\n",
    "                ax.hist(vals, bins=40, alpha=0.6, label=seg_type, color=color, edgecolor=\"white\", linewidth=0.3)\n",
    "        short_name = feat.replace(\"t1_\", \"\").replace(\"t2_\", \"\")\n",
    "        ax.set_title(short_name, fontsize=8)\n",
    "        ax.tick_params(labelsize=6)\n",
    "        ax.legend(fontsize=6)\n",
    "\n",
    "    fig.suptitle(\"Window vs Possession Distributions\", fontsize=10, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000017",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation on non-null numeric features\n",
    "numeric_feats = [\n",
    "    c for c in feature_cols\n",
    "    if df[c].dtype in (pl.Float64, pl.Float32, pl.Int64, pl.Int32)\n",
    "]\n",
    "\n",
    "# Drop columns that are entirely null (correlation undefined)\n",
    "valid_feats = [\n",
    "    c for c in numeric_feats if df[c].drop_nulls().len() > 1\n",
    "]\n",
    "\n",
    "# Use numpy for efficient correlation computation\n",
    "mat = df.select(valid_feats).fill_null(strategy=\"forward\").fill_null(0).to_numpy()\n",
    "corr = np.corrcoef(mat, rowvar=False)\n",
    "# Replace NaN (constant columns) with 0\n",
    "corr = np.nan_to_num(corr, nan=0.0)\n",
    "\n",
    "print(f\"Correlation matrix shape: {corr.shape[0]} x {corr.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000019",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "im = ax.imshow(corr, cmap=\"RdBu_r\", vmin=-1, vmax=1, aspect=\"auto\")\n",
    "\n",
    "# Tier boundary lines\n",
    "tier_boundaries: list[int] = []\n",
    "prev_tier = \"\"\n",
    "for i, col in enumerate(valid_feats):\n",
    "    cur_tier = tier_map.get(col, \"\")\n",
    "    if cur_tier != prev_tier and prev_tier:\n",
    "        tier_boundaries.append(i)\n",
    "    prev_tier = cur_tier\n",
    "\n",
    "for b in tier_boundaries:\n",
    "    ax.axhline(b - 0.5, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
    "    ax.axvline(b - 0.5, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
    "\n",
    "ax.set_title(\"Feature Correlation Matrix\", fontsize=12)\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Abbreviated tick labels (show every Nth)\n",
    "n_feats = len(valid_feats)\n",
    "step = max(1, n_feats // 30)\n",
    "tick_positions = list(range(0, n_feats, step))\n",
    "tick_labels = [\n",
    "    valid_feats[i].replace(\"t1_\", \"\").replace(\"t2_\", \"\").replace(\"t3_\", \"\")\n",
    "    for i in tick_positions\n",
    "]\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(tick_labels, rotation=90, fontsize=5)\n",
    "ax.set_yticks(tick_positions)\n",
    "ax.set_yticklabels(tick_labels, fontsize=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly correlated pairs (|r| > 0.85), excluding self-correlation\n",
    "threshold = 0.85\n",
    "high_corr_pairs: list[tuple[str, str, float]] = []\n",
    "\n",
    "# Only iterate upper triangle\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i + 1, corr.shape[1]):\n",
    "        r = corr[i, j]\n",
    "        if abs(r) > threshold:\n",
    "            high_corr_pairs.append((valid_feats[i], valid_feats[j], float(r)))\n",
    "\n",
    "high_corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "print(f\"Pairs with |r| > {threshold}: {len(high_corr_pairs)}\")\n",
    "if high_corr_pairs:\n",
    "    hc_df = pl.DataFrame(\n",
    "        {\n",
    "            \"feature_a\": [p[0] for p in high_corr_pairs[:20]],\n",
    "            \"feature_b\": [p[1] for p in high_corr_pairs[:20]],\n",
    "            \"correlation\": [round(p[2], 4) for p in high_corr_pairs[:20]],\n",
    "        }\n",
    "    )\n",
    "    print(hc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000021",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Per-Team Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representative features for per-team summary\n",
    "_TEAM_SUMMARY_FEATURES = [\n",
    "    \"t1_pass_count\",\n",
    "    \"t1_pass_completion_rate\",\n",
    "    \"t1_spatial_event_centroid_x\",\n",
    "    \"t1_defend_pressure_count\",\n",
    "    \"t1_context_possession_share\",\n",
    "    \"t2_press_intensity\",\n",
    "]\n",
    "team_feats = [f for f in _TEAM_SUMMARY_FEATURES if f in feature_cols]\n",
    "\n",
    "team_stats = (\n",
    "    df.group_by(\"team_id\")\n",
    "    .agg(\n",
    "        pl.len().alias(\"n_segments\"),\n",
    "        pl.col(\"match_id\").n_unique().alias(\"n_matches\"),\n",
    "        *[\n",
    "            pl.col(f).mean().alias(f\"{f}_mean\")\n",
    "            for f in team_feats\n",
    "        ],\n",
    "        *[\n",
    "            pl.col(f).std().alias(f\"{f}_std\")\n",
    "            for f in team_feats\n",
    "        ],\n",
    "    )\n",
    "    .sort(\"n_segments\", descending=True)\n",
    ")\n",
    "\n",
    "print(team_stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-team null rate\n",
    "team_ids = df[\"team_id\"].unique().sort().to_list()\n",
    "team_null_rows: list[dict[str, object]] = []\n",
    "\n",
    "for tid in team_ids:\n",
    "    team_df = df.filter(pl.col(\"team_id\") == tid)\n",
    "    n = team_df.height\n",
    "    total = n * len(feature_cols)\n",
    "    nulls = sum(team_df[c].null_count() for c in feature_cols)\n",
    "    pct = 100.0 * nulls / total if total > 0 else 0.0\n",
    "    team_null_rows.append(\n",
    "        {\"team_id\": tid, \"n_segments\": n, \"null_rate_pct\": round(pct, 2)}\n",
    "    )\n",
    "\n",
    "team_null_df = pl.DataFrame(team_null_rows).sort(\"null_rate_pct\", descending=True)\n",
    "print(\"Per-team null rate:\")\n",
    "print(team_null_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots: key features by top teams (by segment count)\n",
    "top_teams = (\n",
    "    df.group_by(\"team_id\")\n",
    "    .agg(pl.len().alias(\"cnt\"))\n",
    "    .sort(\"cnt\", descending=True)\n",
    "    .head(8)[\"team_id\"]\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "_BOX_FEATURES = [\n",
    "    \"t1_pass_completion_rate\",\n",
    "    \"t1_spatial_event_centroid_x\",\n",
    "    \"t1_context_possession_share\",\n",
    "]\n",
    "box_features = [f for f in _BOX_FEATURES if f in feature_cols]\n",
    "\n",
    "if box_features and top_teams:\n",
    "    top_df = df.filter(pl.col(\"team_id\").is_in(top_teams))\n",
    "    fig, axes = plt.subplots(1, len(box_features), figsize=(len(box_features) * 4, 4))\n",
    "    if len(box_features) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, feat in zip(axes, box_features):\n",
    "        plot_data: list[list[float]] = []\n",
    "        labels: list[str] = []\n",
    "        for tid in top_teams:\n",
    "            vals = (\n",
    "                top_df.filter(pl.col(\"team_id\") == tid)[feat]\n",
    "                .drop_nulls()\n",
    "                .to_list()\n",
    "            )\n",
    "            if vals:\n",
    "                plot_data.append(vals)\n",
    "                labels.append(str(tid)[:12])\n",
    "        if plot_data:\n",
    "            bp = ax.boxplot(plot_data, labels=labels, patch_artist=True)\n",
    "            for patch in bp[\"boxes\"]:\n",
    "                patch.set_facecolor(\"#4c72b0\")\n",
    "                patch.set_alpha(0.7)\n",
    "            ax.set_title(feat.replace(\"t1_\", \"\"), fontsize=8)\n",
    "            ax.tick_params(axis=\"x\", rotation=45, labelsize=6)\n",
    "            ax.tick_params(axis=\"y\", labelsize=7)\n",
    "\n",
    "    fig.suptitle(\"Feature Distributions by Team (top 8)\", fontsize=10, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000025",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR-based outlier detection per feature\n",
    "outlier_summary: list[dict[str, object]] = []\n",
    "\n",
    "for feat in tqdm(feature_cols, desc=\"Detecting outliers\"):\n",
    "    col = df[feat].drop_nulls()\n",
    "    n_valid = col.len()\n",
    "    if n_valid < 10:\n",
    "        continue\n",
    "    q1 = col.quantile(0.25)\n",
    "    q3 = col.quantile(0.75)\n",
    "    if q1 is None or q3 is None:\n",
    "        continue\n",
    "    iqr = q3 - q1\n",
    "    if iqr == 0:\n",
    "        continue\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    n_outliers = col.filter((col < lower) | (col > upper)).len()\n",
    "    outlier_pct = 100.0 * n_outliers / n_valid\n",
    "    outlier_summary.append(\n",
    "        {\n",
    "            \"feature\": feat,\n",
    "            \"n_outliers\": n_outliers,\n",
    "            \"outlier_pct\": round(outlier_pct, 2),\n",
    "            \"q1\": round(float(q1), 4),\n",
    "            \"q3\": round(float(q3), 4),\n",
    "            \"iqr\": round(float(iqr), 4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "outlier_df = (\n",
    "    pl.DataFrame(outlier_summary)\n",
    "    .sort(\"outlier_pct\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"Top 15 features by outlier percentage (IQR method):\")\n",
    "print(outlier_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier rate distribution\n",
    "if outlier_df.height > 0:\n",
    "    fig, ax = plt.subplots(figsize=(7, 3.5))\n",
    "    ax.hist(\n",
    "        outlier_df[\"outlier_pct\"].to_numpy(),\n",
    "        bins=30,\n",
    "        color=\"#c44e52\",\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=0.4,\n",
    "    )\n",
    "    ax.set_xlabel(\"Outlier % (IQR)\")\n",
    "    ax.set_ylabel(\"Number of features\")\n",
    "    ax.set_title(\"Distribution of Per-Feature Outlier Rates\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000028",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Temporal Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment count by match minute\n",
    "if \"match_minute\" in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 3.5))\n",
    "    for seg_type, color in [(\"window\", \"#4c72b0\"), (\"possession\", \"#dd8452\")]:\n",
    "        seg_df = df.filter(pl.col(\"segment_type\") == seg_type)\n",
    "        if seg_df.height > 0:\n",
    "            vals = seg_df[\"match_minute\"].drop_nulls().to_numpy()\n",
    "            ax.hist(\n",
    "                vals, bins=90, alpha=0.6, label=seg_type,\n",
    "                color=color, edgecolor=\"white\", linewidth=0.3,\n",
    "            )\n",
    "    ax.set_xlabel(\"Match Minute\")\n",
    "    ax.set_ylabel(\"Segment Count\")\n",
    "    ax.set_title(\"Temporal Coverage: Segments by Match Minute\")\n",
    "    ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segments per period\n",
    "period_counts = (\n",
    "    df.group_by(\"period\", \"segment_type\")\n",
    "    .agg(pl.len().alias(\"n_segments\"))\n",
    "    .sort(\"period\", \"segment_type\")\n",
    ")\n",
    "print(\"Segments per period:\")\n",
    "print(period_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segments per match histogram\n",
    "segs_per_match = (\n",
    "    df.group_by(\"match_id\", \"team_id\")\n",
    "    .agg(pl.len().alias(\"n_segments\"))\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3.5))\n",
    "ax.hist(\n",
    "    segs_per_match[\"n_segments\"].to_numpy(),\n",
    "    bins=40, color=\"#55a868\", edgecolor=\"white\", linewidth=0.3,\n",
    ")\n",
    "ax.set_xlabel(\"Segments per (match, team)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Segment Counts per Match-Team\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Median segments per (match, team): {segs_per_match['n_segments'].median():.0f}\")\n",
    "print(f\"Min: {segs_per_match['n_segments'].min()}, Max: {segs_per_match['n_segments'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000032",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Key findings from this data-quality report:\n",
    "\n",
    "1. **Null rates** -- Tier 3 features have the highest null rates (expected, as 360 data is not available for all matches). Check the null-rate bar chart above for specifics.\n",
    "2. **Feature distributions** -- Some counting features are heavily right-skewed (shots, fouls). Rates and percentages are generally bounded and well-behaved.\n",
    "3. **Correlation** -- Highly correlated feature pairs may warrant dimensionality reduction or feature selection before modeling.\n",
    "4. **Per-team variation** -- Teams with more matches naturally have more segments. Null rates should be roughly uniform across teams (differences indicate 360 availability).\n",
    "5. **Temporal coverage** -- Segment density is roughly uniform across match minutes, confirming the windowing strategy provides balanced coverage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
