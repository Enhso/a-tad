{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0000001",
   "metadata": {},
   "source": [
    "# 02 -- Feature Analysis\n",
    "\n",
    "Exploratory analysis of the extracted feature matrix to inform\n",
    "modeling decisions (dimensionality reduction, feature selection,\n",
    "model architecture).\n",
    "\n",
    "**Sections:**\n",
    "1. Data loading & preprocessing\n",
    "2. PCA: scree plot & explained variance\n",
    "3. PCA: component loadings & feature importance\n",
    "4. UMAP: team separation\n",
    "5. UMAP: temporal structure\n",
    "6. Feature redundancy: hierarchical clustering\n",
    "7. Correlation block structure\n",
    "8. Key observations & modeling recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "from umap import UMAP\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "from tactical.models.preprocessing import PreprocessingPipeline\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=0.9)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "FEATURES_PATH = PROJECT_ROOT / \"data\" / \"output\" / \"features.parquet\"\n",
    "\n",
    "METADATA_COLS: set[str] = {\n",
    "    \"match_id\",\n",
    "    \"team_id\",\n",
    "    \"segment_type\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "    \"period\",\n",
    "    \"match_minute\",\n",
    "}\n",
    "\n",
    "TIER_PALETTE: dict[str, str] = {\n",
    "    \"Tier 1\": \"#4c72b0\",\n",
    "    \"Tier 2\": \"#dd8452\",\n",
    "    \"Tier 3\": \"#55a868\",\n",
    "    \"Unknown\": \"#999999\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000003",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURES_PATH.exists():\n",
    "    df = pl.read_parquet(FEATURES_PATH)\n",
    "    print(f\"Loaded {FEATURES_PATH}\")\n",
    "else:\n",
    "    print(\n",
    "        f\"{FEATURES_PATH} not found.\\n\"\n",
    "        \"Run `python scripts/run_feature_extraction.py` first.\"\n",
    "    )\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000005",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols: list[str] = sorted(\n",
    "    c for c in df.columns if c not in METADATA_COLS\n",
    ")\n",
    "\n",
    "tier_map: dict[str, str] = {}\n",
    "for col in feature_cols:\n",
    "    if col.startswith(\"t1_\"):\n",
    "        tier_map[col] = \"Tier 1\"\n",
    "    elif col.startswith(\"t2_\"):\n",
    "        tier_map[col] = \"Tier 2\"\n",
    "    elif col.startswith(\"t3_\"):\n",
    "        tier_map[col] = \"Tier 3\"\n",
    "    else:\n",
    "        tier_map[col] = \"Unknown\"\n",
    "\n",
    "# Focus on window segments for PCA/UMAP (consistent segment length)\n",
    "df_win = df.filter(pl.col(\"segment_type\") == \"window\")\n",
    "\n",
    "print(f\"Total rows: {df.height:,}  |  Window rows: {df_win.height:,}\")\n",
    "print(f\"Feature columns: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PreprocessingPipeline for Tier 1+2 features (model-ready subset)\n",
    "# Tier 3 features are excluded because they contain nulls for most matches\n",
    "pipeline = PreprocessingPipeline(\n",
    "    feature_prefix=\"t\",\n",
    "    null_strategy=\"drop_rows\",\n",
    "    pca_variance_threshold=None,  # no PCA yet -- we analyze raw scaled space first\n",
    ")\n",
    "\n",
    "# Fit on window segments only\n",
    "X_scaled = pipeline.fit_transform(df_win)\n",
    "retained_mask = pipeline.get_retained_row_mask(df_win)\n",
    "df_clean = df_win.filter(pl.Series(retained_mask))\n",
    "\n",
    "scaled_feature_names: list[str] = pipeline._feature_columns\n",
    "\n",
    "print(f\"Scaled matrix shape: {X_scaled.shape}\")\n",
    "print(f\"Rows retained after null handling: {X_scaled.shape[0]:,} / {df_win.height:,}\")\n",
    "print(f\"Features used: {X_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000007",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. PCA: Scree Plot & Explained Variance\n",
    "\n",
    "Fit a full PCA to understand the intrinsic dimensionality of the\n",
    "feature space and determine how many components are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000008",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_components = min(X_scaled.shape[0], X_scaled.shape[1])\n",
    "pca_full = PCA(n_components=max_components)\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "explained = pca_full.explained_variance_ratio_\n",
    "cumulative = np.cumsum(explained)\n",
    "\n",
    "# Key variance thresholds\n",
    "for thresh in (0.80, 0.90, 0.95, 0.99):\n",
    "    n_comp = int(np.searchsorted(cumulative, thresh) + 1)\n",
    "    print(f\"  {thresh:.0%} variance explained by {n_comp} / {max_components} components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot + cumulative explained variance\n",
    "n_show = min(40, max_components)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Left: individual explained variance\n",
    "ax1.bar(\n",
    "    range(1, n_show + 1),\n",
    "    explained[:n_show] * 100,\n",
    "    color=\"#4c72b0\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=0.4,\n",
    ")\n",
    "ax1.set_xlabel(\"Principal Component\")\n",
    "ax1.set_ylabel(\"Variance Explained (%)\")\n",
    "ax1.set_title(\"Scree Plot\")\n",
    "ax1.set_xlim(0.5, n_show + 0.5)\n",
    "\n",
    "# Right: cumulative\n",
    "ax2.plot(\n",
    "    range(1, max_components + 1),\n",
    "    cumulative * 100,\n",
    "    color=\"#4c72b0\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "for thresh, ls in [(80, \":\"), (90, \"--\"), (95, \"-.\")]:\n",
    "    ax2.axhline(thresh, color=\"#c44e52\", linestyle=ls, linewidth=0.8, alpha=0.7)\n",
    "    n_at = int(np.searchsorted(cumulative, thresh / 100) + 1)\n",
    "    ax2.annotate(\n",
    "        f\"{thresh}% @ {n_at}\",\n",
    "        xy=(n_at, thresh),\n",
    "        fontsize=7,\n",
    "        color=\"#c44e52\",\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "ax2.set_xlabel(\"Number of Components\")\n",
    "ax2.set_ylabel(\"Cumulative Variance (%)\")\n",
    "ax2.set_title(\"Cumulative Explained Variance\")\n",
    "\n",
    "fig.suptitle(\"PCA Dimensionality Analysis\", fontsize=11, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000010",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. PCA: Component Loadings & Feature Importance\n",
    "\n",
    "Identify which original features contribute most to the top\n",
    "principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top N components to inspect\n",
    "N_TOP_PC = min(6, max_components)\n",
    "N_TOP_FEATURES = 10\n",
    "\n",
    "loadings = pca_full.components_[:N_TOP_PC]  # (N_TOP_PC, n_features)\n",
    "\n",
    "loading_rows: list[dict[str, object]] = []\n",
    "for pc_idx in range(N_TOP_PC):\n",
    "    abs_loadings = np.abs(loadings[pc_idx])\n",
    "    top_indices = np.argsort(abs_loadings)[::-1][:N_TOP_FEATURES]\n",
    "    for rank, feat_idx in enumerate(top_indices):\n",
    "        loading_rows.append(\n",
    "            {\n",
    "                \"PC\": pc_idx + 1,\n",
    "                \"rank\": rank + 1,\n",
    "                \"feature\": scaled_feature_names[feat_idx],\n",
    "                \"loading\": round(float(loadings[pc_idx, feat_idx]), 4),\n",
    "                \"abs_loading\": round(float(abs_loadings[feat_idx]), 4),\n",
    "                \"tier\": tier_map.get(scaled_feature_names[feat_idx], \"Unknown\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "loading_df = pl.DataFrame(loading_rows)\n",
    "for pc in range(1, N_TOP_PC + 1):\n",
    "    subset = loading_df.filter(pl.col(\"PC\") == pc)\n",
    "    var_pct = explained[pc - 1] * 100\n",
    "    print(f\"\\n--- PC{pc} ({var_pct:.1f}% variance) ---\")\n",
    "    print(subset.select(\"rank\", \"feature\", \"loading\", \"tier\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of top feature loadings across first N components\n",
    "# Collect all features that appear in any top-N list\n",
    "top_features_set: set[str] = set()\n",
    "for pc_idx in range(N_TOP_PC):\n",
    "    abs_l = np.abs(loadings[pc_idx])\n",
    "    top_idx = np.argsort(abs_l)[::-1][:N_TOP_FEATURES]\n",
    "    for i in top_idx:\n",
    "        top_features_set.add(scaled_feature_names[i])\n",
    "\n",
    "top_features_sorted = sorted(top_features_set)\n",
    "feat_indices = [scaled_feature_names.index(f) for f in top_features_sorted]\n",
    "\n",
    "loading_matrix = loadings[:, feat_indices]  # (N_TOP_PC, len(top_features_sorted))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, max(4, N_TOP_PC * 0.8)))\n",
    "im = ax.imshow(loading_matrix, cmap=\"RdBu_r\", aspect=\"auto\", vmin=-0.5, vmax=0.5)\n",
    "\n",
    "ax.set_yticks(range(N_TOP_PC))\n",
    "ax.set_yticklabels([f\"PC{i+1} ({explained[i]*100:.1f}%)\" for i in range(N_TOP_PC)], fontsize=8)\n",
    "ax.set_xticks(range(len(top_features_sorted)))\n",
    "short_names = [\n",
    "    f.replace(\"t1_\", \"\").replace(\"t2_\", \"\").replace(\"t3_\", \"\")\n",
    "    for f in top_features_sorted\n",
    "]\n",
    "ax.set_xticklabels(short_names, rotation=90, fontsize=6)\n",
    "ax.set_title(\"PCA Loadings: Top Contributing Features\", fontsize=11)\n",
    "fig.colorbar(im, ax=ax, fraction=0.02, pad=0.04, label=\"Loading\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate feature importance: sum of squared loadings across\n",
    "# components weighted by explained variance\n",
    "n_for_importance = int(np.searchsorted(cumulative, 0.95) + 1)\n",
    "weights = explained[:n_for_importance]\n",
    "importance = (pca_full.components_[:n_for_importance] ** 2) * weights[:, np.newaxis]\n",
    "importance_scores = importance.sum(axis=0)  # (n_features,)\n",
    "\n",
    "importance_order = np.argsort(importance_scores)[::-1]\n",
    "\n",
    "n_show_imp = min(25, len(importance_order))\n",
    "top_imp_names = [scaled_feature_names[i] for i in importance_order[:n_show_imp]]\n",
    "top_imp_scores = importance_scores[importance_order[:n_show_imp]]\n",
    "top_imp_tiers = [tier_map.get(n, \"Unknown\") for n in top_imp_names]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, max(4, n_show_imp * 0.3)))\n",
    "bar_colors = [TIER_PALETTE.get(t, \"#999999\") for t in top_imp_tiers]\n",
    "y_pos = np.arange(n_show_imp)\n",
    "ax.barh(y_pos, top_imp_scores, color=bar_colors, edgecolor=\"white\", linewidth=0.4)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(\n",
    "    [n.replace(\"t1_\", \"\").replace(\"t2_\", \"\").replace(\"t3_\", \"\") for n in top_imp_names],\n",
    "    fontsize=7,\n",
    ")\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Weighted Squared Loading (importance)\")\n",
    "ax.set_title(f\"Top {n_show_imp} Features by PCA Importance (95% variance)\", fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "handles = [\n",
    "    Patch(facecolor=c, label=t)\n",
    "    for t, c in TIER_PALETTE.items()\n",
    "    if t in set(top_imp_tiers)\n",
    "]\n",
    "ax.legend(handles=handles, loc=\"lower right\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000014",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. UMAP: Team Separation\n",
    "\n",
    "Project the feature space into 2D with UMAP and colour by team\n",
    "to assess whether different teams occupy distinct regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to PCA space first (faster UMAP, denoised)\n",
    "n_pca_for_umap = int(np.searchsorted(cumulative, 0.95) + 1)\n",
    "X_pca = pca_full.transform(X_scaled)[:, :n_pca_for_umap]\n",
    "\n",
    "reducer = UMAP(n_components=2, n_neighbors=30, min_dist=0.3, random_state=42, n_jobs=1)\n",
    "X_umap = reducer.fit_transform(X_pca)\n",
    "\n",
    "print(f\"UMAP input: {X_pca.shape} -> output: {X_umap.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour by team_id\n",
    "team_ids = df_clean[\"team_id\"].to_list()\n",
    "unique_teams = sorted(set(team_ids))\n",
    "n_teams = len(unique_teams)\n",
    "\n",
    "# Build a color map: use a qualitative palette\n",
    "cmap_teams = plt.cm.get_cmap(\"tab20\", max(n_teams, 2))\n",
    "team_to_idx = {t: i for i, t in enumerate(unique_teams)}\n",
    "team_colors = np.array([team_to_idx[t] for t in team_ids])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(\n",
    "    X_umap[:, 0],\n",
    "    X_umap[:, 1],\n",
    "    c=team_colors,\n",
    "    cmap=cmap_teams,\n",
    "    s=4,\n",
    "    alpha=0.5,\n",
    "    edgecolors=\"none\",\n",
    ")\n",
    "ax.set_xlabel(\"UMAP-1\")\n",
    "ax.set_ylabel(\"UMAP-2\")\n",
    "ax.set_title(f\"UMAP Projection Coloured by Team ({n_teams} teams)\", fontsize=11)\n",
    "\n",
    "# Legend: show up to 15 teams to keep it readable\n",
    "max_legend = min(15, n_teams)\n",
    "legend_handles = [\n",
    "    plt.Line2D(\n",
    "        [0], [0],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        markerfacecolor=cmap_teams(team_to_idx[t]),\n",
    "        markersize=5,\n",
    "        label=str(t)[:20],\n",
    "    )\n",
    "    for t in unique_teams[:max_legend]\n",
    "]\n",
    "if n_teams > max_legend:\n",
    "    legend_handles.append(\n",
    "        plt.Line2D([0], [0], marker=\"\", color=\"w\", label=f\"... +{n_teams - max_legend} more\")\n",
    "    )\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.01, 1),\n",
    "    fontsize=6,\n",
    "    frameon=True,\n",
    "    ncol=1,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight individual teams: overlay the densest teams\n",
    "team_counts = (\n",
    "    df_clean.group_by(\"team_id\")\n",
    "    .agg(pl.len().alias(\"cnt\"))\n",
    "    .sort(\"cnt\", descending=True)\n",
    ")\n",
    "top_n_highlight = min(6, team_counts.height)\n",
    "highlight_teams = team_counts.head(top_n_highlight)[\"team_id\"].to_list()\n",
    "\n",
    "n_cols_grid = min(3, top_n_highlight)\n",
    "n_rows_grid = (top_n_highlight + n_cols_grid - 1) // n_cols_grid\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows_grid, n_cols_grid,\n",
    "    figsize=(n_cols_grid * 4, n_rows_grid * 3.5),\n",
    ")\n",
    "axes_flat = np.array(axes).flatten()\n",
    "\n",
    "team_ids_arr = np.array(team_ids)\n",
    "\n",
    "for idx, tid in enumerate(highlight_teams):\n",
    "    ax = axes_flat[idx]\n",
    "    mask = team_ids_arr == tid\n",
    "    ax.scatter(\n",
    "        X_umap[~mask, 0], X_umap[~mask, 1],\n",
    "        c=\"#dddddd\", s=2, alpha=0.3, edgecolors=\"none\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_umap[mask, 0], X_umap[mask, 1],\n",
    "        c=\"#c44e52\", s=6, alpha=0.7, edgecolors=\"none\",\n",
    "    )\n",
    "    ax.set_title(str(tid)[:25], fontsize=8)\n",
    "    ax.tick_params(labelsize=5)\n",
    "    ax.set_xlabel(\"UMAP-1\", fontsize=6)\n",
    "    ax.set_ylabel(\"UMAP-2\", fontsize=6)\n",
    "\n",
    "for idx in range(top_n_highlight, len(axes_flat)):\n",
    "    axes_flat[idx].set_visible(False)\n",
    "\n",
    "fig.suptitle(\"UMAP: Individual Team Overlays (top by segment count)\", fontsize=10, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000018",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. UMAP: Temporal & Contextual Structure\n",
    "\n",
    "Colour UMAP by match minute, period, and score differential\n",
    "to check whether temporal or game-state structure is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour by match minute\n",
    "match_minutes = df_clean[\"match_minute\"].to_numpy().astype(float)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Match minute\n",
    "sc1 = axes[0].scatter(\n",
    "    X_umap[:, 0], X_umap[:, 1],\n",
    "    c=match_minutes, cmap=\"viridis\", s=4, alpha=0.5, edgecolors=\"none\",\n",
    ")\n",
    "axes[0].set_title(\"Coloured by Match Minute\", fontsize=10)\n",
    "axes[0].set_xlabel(\"UMAP-1\")\n",
    "axes[0].set_ylabel(\"UMAP-2\")\n",
    "fig.colorbar(sc1, ax=axes[0], fraction=0.04, pad=0.04, label=\"Minute\")\n",
    "\n",
    "# Period\n",
    "periods = df_clean[\"period\"].to_numpy().astype(float)\n",
    "sc2 = axes[1].scatter(\n",
    "    X_umap[:, 0], X_umap[:, 1],\n",
    "    c=periods, cmap=\"Set1\", s=4, alpha=0.5, edgecolors=\"none\",\n",
    ")\n",
    "axes[1].set_title(\"Coloured by Period\", fontsize=10)\n",
    "axes[1].set_xlabel(\"UMAP-1\")\n",
    "axes[1].set_ylabel(\"UMAP-2\")\n",
    "fig.colorbar(sc2, ax=axes[1], fraction=0.04, pad=0.04, label=\"Period\")\n",
    "\n",
    "fig.suptitle(\"UMAP: Temporal Structure\", fontsize=11, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour by score differential and possession share (if available)\n",
    "_CONTEXT_FEATURES = [\n",
    "    (\"t1_context_score_differential\", \"Score Differential\"),\n",
    "    (\"t1_context_possession_share\", \"Possession Share\"),\n",
    "]\n",
    "available_ctx = [\n",
    "    (col, label) for col, label in _CONTEXT_FEATURES\n",
    "    if col in df_clean.columns\n",
    "]\n",
    "\n",
    "if available_ctx:\n",
    "    fig, axes = plt.subplots(\n",
    "        1, len(available_ctx),\n",
    "        figsize=(6 * len(available_ctx), 5),\n",
    "    )\n",
    "    if len(available_ctx) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (col, label) in zip(axes, available_ctx):\n",
    "        vals = df_clean[col].fill_null(0).to_numpy().astype(float)\n",
    "        sc = ax.scatter(\n",
    "            X_umap[:, 0], X_umap[:, 1],\n",
    "            c=vals, cmap=\"RdYlBu_r\", s=4, alpha=0.5, edgecolors=\"none\",\n",
    "        )\n",
    "        ax.set_title(f\"Coloured by {label}\", fontsize=10)\n",
    "        ax.set_xlabel(\"UMAP-1\")\n",
    "        ax.set_ylabel(\"UMAP-2\")\n",
    "        fig.colorbar(sc, ax=ax, fraction=0.04, pad=0.04, label=label)\n",
    "\n",
    "    fig.suptitle(\"UMAP: Game-State Context\", fontsize=11, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No context features available for UMAP colouring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour by a representative tactical feature\n",
    "_TACTICAL_FEATURES = [\n",
    "    (\"t1_spatial_event_centroid_x\", \"Event Centroid X\"),\n",
    "    (\"t2_press_intensity\", \"Pressing Intensity\"),\n",
    "    (\"t2_shape_engagement_line\", \"Engagement Line\"),\n",
    "    (\"t1_pass_completion_rate\", \"Pass Completion Rate\"),\n",
    "]\n",
    "available_tac = [\n",
    "    (col, label) for col, label in _TACTICAL_FEATURES\n",
    "    if col in df_clean.columns\n",
    "]\n",
    "\n",
    "if available_tac:\n",
    "    n_tac = len(available_tac)\n",
    "    n_cols_g = min(2, n_tac)\n",
    "    n_rows_g = (n_tac + n_cols_g - 1) // n_cols_g\n",
    "    fig, axes = plt.subplots(n_rows_g, n_cols_g, figsize=(n_cols_g * 6, n_rows_g * 4.5))\n",
    "    axes_flat = np.array(axes).flatten()\n",
    "\n",
    "    for idx, (col, label) in enumerate(available_tac):\n",
    "        ax = axes_flat[idx]\n",
    "        vals = df_clean[col].fill_null(0).to_numpy().astype(float)\n",
    "        sc = ax.scatter(\n",
    "            X_umap[:, 0], X_umap[:, 1],\n",
    "            c=vals, cmap=\"coolwarm\", s=4, alpha=0.5, edgecolors=\"none\",\n",
    "        )\n",
    "        ax.set_title(f\"Coloured by {label}\", fontsize=9)\n",
    "        ax.set_xlabel(\"UMAP-1\", fontsize=8)\n",
    "        ax.set_ylabel(\"UMAP-2\", fontsize=8)\n",
    "        fig.colorbar(sc, ax=ax, fraction=0.04, pad=0.04)\n",
    "\n",
    "    for idx in range(n_tac, len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"UMAP: Tactical Feature Gradients\", fontsize=11, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000022",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Feature Redundancy: Hierarchical Clustering\n",
    "\n",
    "Cluster features by their absolute correlation to identify\n",
    "redundant groups that could be removed or merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix on scaled features\n",
    "corr_matrix = np.corrcoef(X_scaled, rowvar=False)\n",
    "corr_matrix = np.nan_to_num(corr_matrix, nan=0.0)\n",
    "\n",
    "# Convert correlation to distance: d = 1 - |r|\n",
    "dist_matrix = 1.0 - np.abs(corr_matrix)\n",
    "np.fill_diagonal(dist_matrix, 0.0)\n",
    "# Ensure symmetry and non-negativity\n",
    "dist_matrix = np.clip((dist_matrix + dist_matrix.T) / 2, 0, None)\n",
    "\n",
    "condensed = squareform(dist_matrix, checks=False)\n",
    "linkage_matrix = linkage(condensed, method=\"average\")\n",
    "\n",
    "print(f\"Feature correlation matrix: {corr_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrogram\n",
    "short_labels = [\n",
    "    f.replace(\"t1_\", \"\").replace(\"t2_\", \"\").replace(\"t3_\", \"\")\n",
    "    for f in scaled_feature_names\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, max(6, len(scaled_feature_names) * 0.18)))\n",
    "dendro = dendrogram(\n",
    "    linkage_matrix,\n",
    "    labels=short_labels,\n",
    "    orientation=\"left\",\n",
    "    leaf_font_size=5,\n",
    "    color_threshold=0.3,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.axvline(0.15, color=\"#c44e52\", linestyle=\"--\", linewidth=0.8, label=\"r = 0.85 threshold\")\n",
    "ax.axvline(0.30, color=\"#dd8452\", linestyle=\"--\", linewidth=0.8, label=\"r = 0.70 threshold\")\n",
    "ax.set_xlabel(\"Distance (1 - |correlation|)\")\n",
    "ax.set_title(\"Hierarchical Clustering of Features by Correlation\", fontsize=11)\n",
    "ax.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify redundant feature groups at |r| > 0.85 (distance < 0.15)\n",
    "REDUNDANCY_THRESHOLD = 0.15\n",
    "cluster_labels = fcluster(linkage_matrix, t=REDUNDANCY_THRESHOLD, criterion=\"distance\")\n",
    "\n",
    "# Find clusters with more than one member\n",
    "cluster_to_features: dict[int, list[str]] = {}\n",
    "for feat, cid in zip(scaled_feature_names, cluster_labels):\n",
    "    cluster_to_features.setdefault(int(cid), []).append(feat)\n",
    "\n",
    "redundant_groups = {\n",
    "    cid: feats for cid, feats in cluster_to_features.items() if len(feats) > 1\n",
    "}\n",
    "\n",
    "print(f\"Redundant groups (|r| > 0.85): {len(redundant_groups)}\")\n",
    "print(f\"Total features in redundant groups: {sum(len(f) for f in redundant_groups.values())}\")\n",
    "print(f\"Singleton features: {sum(1 for f in cluster_to_features.values() if len(f) == 1)}\")\n",
    "print()\n",
    "\n",
    "for i, (cid, feats) in enumerate(sorted(redundant_groups.items())):\n",
    "    print(f\"  Group {i+1}: {feats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000026",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Correlation Block Structure\n",
    "\n",
    "Reorder the correlation matrix using the hierarchical clustering\n",
    "to reveal block-diagonal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder correlation matrix by dendrogram leaf order\n",
    "leaf_order = dendro[\"leaves\"]\n",
    "corr_reordered = corr_matrix[np.ix_(leaf_order, leaf_order)]\n",
    "reordered_names = [scaled_feature_names[i] for i in leaf_order]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "im = ax.imshow(corr_reordered, cmap=\"RdBu_r\", vmin=-1, vmax=1, aspect=\"auto\")\n",
    "\n",
    "# Tier boundary annotations on the reordered axis\n",
    "n_feats = len(reordered_names)\n",
    "step = max(1, n_feats // 30)\n",
    "tick_positions = list(range(0, n_feats, step))\n",
    "tick_labels = [\n",
    "    reordered_names[i].replace(\"t1_\", \"\").replace(\"t2_\", \"\").replace(\"t3_\", \"\")\n",
    "    for i in tick_positions\n",
    "]\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(tick_labels, rotation=90, fontsize=5)\n",
    "ax.set_yticks(tick_positions)\n",
    "ax.set_yticklabels(tick_labels, fontsize=5)\n",
    "ax.set_title(\"Correlation Matrix (reordered by hierarchical clustering)\", fontsize=11)\n",
    "fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of absolute pairwise correlations (upper triangle)\n",
    "upper_idx = np.triu_indices(corr_matrix.shape[0], k=1)\n",
    "abs_corrs = np.abs(corr_matrix[upper_idx])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3.5))\n",
    "ax.hist(abs_corrs, bins=50, color=\"#4c72b0\", edgecolor=\"white\", linewidth=0.4)\n",
    "ax.axvline(0.85, color=\"#c44e52\", linestyle=\"--\", linewidth=1, label=\"|r|=0.85\")\n",
    "ax.axvline(0.70, color=\"#dd8452\", linestyle=\"--\", linewidth=1, label=\"|r|=0.70\")\n",
    "ax.set_xlabel(\"|Pairwise Correlation|\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Absolute Pairwise Feature Correlations\")\n",
    "ax.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "n_pairs = len(abs_corrs)\n",
    "n_high = int(np.sum(abs_corrs > 0.85))\n",
    "n_moderate = int(np.sum(abs_corrs > 0.70))\n",
    "print(f\"Total feature pairs: {n_pairs:,}\")\n",
    "print(f\"Pairs with |r| > 0.85: {n_high} ({100*n_high/n_pairs:.1f}%)\")\n",
    "print(f\"Pairs with |r| > 0.70: {n_moderate} ({100*n_moderate/n_pairs:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effective dimensionality estimates\n",
    "eigenvalues = pca_full.explained_variance_\n",
    "\n",
    "# Participation ratio: (sum(lambda))^2 / sum(lambda^2)\n",
    "participation_ratio = float(eigenvalues.sum() ** 2 / (eigenvalues ** 2).sum())\n",
    "\n",
    "# Kaiser criterion: eigenvalue > 1 (on correlation matrix = eigenvalue > mean)\n",
    "mean_eigenvalue = eigenvalues.mean()\n",
    "n_kaiser = int(np.sum(eigenvalues > mean_eigenvalue))\n",
    "\n",
    "# 95% cumulative variance\n",
    "n_95 = int(np.searchsorted(cumulative, 0.95) + 1)\n",
    "\n",
    "print(\"Effective dimensionality estimates:\")\n",
    "print(f\"  Participation ratio       : {participation_ratio:.1f}\")\n",
    "print(f\"  Kaiser criterion (> mean) : {n_kaiser}\")\n",
    "print(f\"  95% cumulative variance   : {n_95}\")\n",
    "print(f\"  Original feature count    : {X_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000030",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Key Observations & Modeling Recommendations\n",
    "\n",
    "### Dimensionality\n",
    "\n",
    "- The PCA scree plot shows how quickly variance is concentrated in the\n",
    "  first few components. Check the 95% threshold above to determine the\n",
    "  practical dimensionality.\n",
    "- The participation ratio and Kaiser criterion provide complementary\n",
    "  estimates. If these converge (e.g., all around 10-15), the effective\n",
    "  dimensionality is well-defined.\n",
    "- **Recommendation:** Use PCA with 95% variance retention as the\n",
    "  default for the `PreprocessingPipeline` (`pca_variance_threshold=0.95`).\n",
    "\n",
    "### Team Separation in UMAP\n",
    "\n",
    "- If teams cluster into distinct regions of the UMAP embedding, the\n",
    "  feature space captures team-level tactical identity. This supports\n",
    "  per-team or across-team modeling.\n",
    "- If teams are intermixed, the feature space primarily captures\n",
    "  *situational* variation (game state, phase of play) rather than\n",
    "  *team identity*. This is favorable for discovering universal\n",
    "  tactical states.\n",
    "- Check the individual team overlays (Section 4) for specific cases.\n",
    "\n",
    "### Temporal Structure\n",
    "\n",
    "- Gradients in match minute or period on the UMAP plot indicate that\n",
    "  the feature space encodes temporal information (early-match vs.\n",
    "  late-match behavior).\n",
    "- If score differential produces visible gradients, the features\n",
    "  are sensitive to game state -- important for tactical discovery.\n",
    "- **Implication:** HMM may capture temporal dynamics better than GMM\n",
    "  if strong temporal structure is present.\n",
    "\n",
    "### Feature Redundancy\n",
    "\n",
    "- The dendrogram reveals groups of highly correlated features that\n",
    "  carry essentially the same information.\n",
    "- Each redundant group (|r| > 0.85) could be represented by a single\n",
    "  feature or collapsed via PCA.\n",
    "- **Recommendation:** Prefer PCA-based reduction over manual feature\n",
    "  selection. PCA naturally handles correlated features.\n",
    "\n",
    "### Modeling Implications\n",
    "\n",
    "1. **PCA retention:** Use the 95% threshold identified above.\n",
    "2. **Null strategy:** Tier 1+2 features should have negligible nulls;\n",
    "   `drop_rows` is safe. Exclude Tier 3 from model input.\n",
    "3. **Model input:** Feed PCA-reduced features to GMM/HMM.\n",
    "4. **Number of clusters (K):** The UMAP plots provide a visual prior\n",
    "   for the expected number of natural groupings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
