{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0000001",
   "metadata": {},
   "source": [
    "# VAE Discovery: Latent Tactical State Exploration\n",
    "\n",
    "Train a beta-VAE on combined match feature data, extract latent codes,\n",
    "and correlate each latent dimension with observable features to produce\n",
    "an interpretation table.\n",
    "\n",
    "**Target environment:** Kaggle (2 x T4 GPUs via `DataParallel`)\n",
    "\n",
    "**Sections:**\n",
    "1. Setup & GPU detection\n",
    "2. Data loading & preprocessing\n",
    "3. VAE training (multi-GPU)\n",
    "4. Training diagnostics\n",
    "5. Latent code extraction\n",
    "6. Latent-feature Pearson correlation\n",
    "7. Interpretation table (top-5 features per dimension)\n",
    "8. Latent space UMAP visualisation\n",
    "9. Summary & next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from umap import UMAP\n",
    "\n",
    "# -- Project imports ------------------------------------------------\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "from tactical.config import VAEConfig\n",
    "from tactical.models.preprocessing import PreprocessingPipeline\n",
    "from tactical.models.vae import TacticalVAEModule, vae_loss\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=0.9)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "FEATURES_PATH = PROJECT_ROOT / \"data\" / \"output\" / \"features.parquet\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"output\" / \"vae_discovery\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METADATA_COLS: set[str] = {\n",
    "    \"match_id\",\n",
    "    \"team_id\",\n",
    "    \"segment_type\",\n",
    "    \"start_time\",\n",
    "    \"end_time\",\n",
    "    \"period\",\n",
    "    \"match_minute\",\n",
    "}\n",
    "\n",
    "TIER_PATTERN = re.compile(r\"^t(\\d+)_\")\n",
    "MAX_FEATURE_TIER = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000003",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & GPU Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000004",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "print(f\"Device : {device}  |  GPUs available: {n_gpus}\")\n",
    "for i in range(n_gpus):\n",
    "    name = torch.cuda.get_device_name(i)\n",
    "    mem = torch.cuda.get_device_properties(i).total_mem / 1024**3\n",
    "    print(f\"  GPU {i}: {name}  ({mem:.1f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000005",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading & Preprocessing\n",
    "\n",
    "Load the combined feature matrix, filter to **window** segments and\n",
    "Tier 1+2 features, then z-score normalise **without PCA** so that\n",
    "every latent dimension can be correlated back to named features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURES_PATH.exists():\n",
    "    df_raw = pl.read_parquet(FEATURES_PATH)\n",
    "    print(f\"Loaded {FEATURES_PATH}\")\n",
    "else:\n",
    "    print(\n",
    "        f\"{FEATURES_PATH} not found.\\n\"\n",
    "        \"Run `python scripts/run_feature_extraction.py` first.\"\n",
    "    )\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# Keep window segments only (consistent segment length)\n",
    "df_win = df_raw.filter(pl.col(\"segment_type\") == \"window\")\n",
    "\n",
    "# Drop Tier 3+ feature columns (sparse 360 data)\n",
    "tier3_cols = [\n",
    "    c for c in df_win.columns\n",
    "    if (m := TIER_PATTERN.match(c)) and int(m.group(1)) > MAX_FEATURE_TIER\n",
    "]\n",
    "df_win = df_win.drop(tier3_cols)\n",
    "\n",
    "print(f\"Window rows: {df_win.height:,}\")\n",
    "print(f\"Dropped {len(tier3_cols)} Tier 3+ columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess: z-score scaling, median imputation, NO PCA\n",
    "pipeline = PreprocessingPipeline(\n",
    "    feature_prefix=\"t\",\n",
    "    null_strategy=\"impute_median\",\n",
    "    pca_variance_threshold=None,\n",
    ")\n",
    "X = pipeline.fit_transform(df_win)\n",
    "feature_names: list[str] = pipeline._feature_columns\n",
    "retained_mask = pipeline.get_retained_row_mask(df_win)\n",
    "df_retained = df_win.filter(pl.Series(retained_mask))\n",
    "\n",
    "print(f\"Samples : {X.shape[0]:,}\")\n",
    "print(f\"Features: {X.shape[1]} ({len(feature_names)} named columns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000008",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. VAE Training (Multi-GPU)\n",
    "\n",
    "Architecture from spec: beta-VAE with `(256, 128, 64)` encoder,\n",
    "`ReduceLROnPlateau` scheduler, wrapped in `DataParallel` for 2 x T4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000009",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = VAEConfig(\n",
    "    latent_dim=8,\n",
    "    hidden_dims=(256, 128, 64),\n",
    "    beta=4.0,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=512,\n",
    "    n_epochs=150,\n",
    "    dropout=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000010",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(cfg.random_state)\n",
    "np.random.seed(cfg.random_state)  # noqa: NPY002\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "module = TacticalVAEModule(\n",
    "    input_dim=input_dim,\n",
    "    latent_dim=cfg.latent_dim,\n",
    "    hidden_dims=cfg.hidden_dims,\n",
    "    dropout=cfg.dropout,\n",
    ").to(device)\n",
    "\n",
    "# Wrap with DataParallel when multiple GPUs are available\n",
    "if n_gpus > 1:\n",
    "    module_dp: nn.Module = nn.DataParallel(module)\n",
    "    print(f\"DataParallel enabled across {n_gpus} GPUs\")\n",
    "else:\n",
    "    module_dp = module\n",
    "    print(\"Single-device training\")\n",
    "\n",
    "tensor_X = torch.as_tensor(X, dtype=torch.float32, device=device)\n",
    "dataset = TensorDataset(tensor_X)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "optimiser = torch.optim.Adam(module.parameters(), lr=cfg.learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimiser, mode=\"min\", factor=0.5, patience=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000011",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses: list[float] = []\n",
    "epoch_recon_losses: list[float] = []\n",
    "epoch_kl_losses: list[float] = []\n",
    "\n",
    "module_dp.train()\n",
    "\n",
    "for epoch in tqdm(range(cfg.n_epochs), desc=\"VAE training\"):\n",
    "    total_loss = 0.0\n",
    "    total_recon = 0.0\n",
    "    total_kl = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for (batch,) in loader:\n",
    "        recon, mu, logvar = module_dp(batch)\n",
    "        loss, recon_l, kl_l = vae_loss(recon, batch, mu, logvar, beta=cfg.beta)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()  # type: ignore[no-untyped-call]\n",
    "        optimiser.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_recon += recon_l.item()\n",
    "        total_kl += kl_l.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    mean_loss = total_loss / max(n_batches, 1)\n",
    "    mean_recon = total_recon / max(n_batches, 1)\n",
    "    mean_kl = total_kl / max(n_batches, 1)\n",
    "    epoch_losses.append(mean_loss)\n",
    "    epoch_recon_losses.append(mean_recon)\n",
    "    epoch_kl_losses.append(mean_kl)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "module_dp.eval()\n",
    "print(f\"Final loss: {epoch_losses[-1]:.6f}  (recon={epoch_recon_losses[-1]:.6f}, kl={epoch_kl_losses[-1]:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000012",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Training Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "epochs_arr = np.arange(1, len(epoch_losses) + 1)\n",
    "\n",
    "axes[0].plot(epochs_arr, epoch_losses, linewidth=1.2)\n",
    "axes[0].set_title(\"Total Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "\n",
    "axes[1].plot(epochs_arr, epoch_recon_losses, linewidth=1.2, color=\"#dd8452\")\n",
    "axes[1].set_title(\"Reconstruction Loss (MSE)\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "\n",
    "axes[2].plot(epochs_arr, epoch_kl_losses, linewidth=1.2, color=\"#55a868\")\n",
    "axes[2].set_title(\"KL Divergence\")\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].set_ylabel(\"Loss\")\n",
    "\n",
    "fig.suptitle(\"VAE Training Curves\", fontsize=13, y=1.02)\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"vae_training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000014",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Latent Code Extraction\n",
    "\n",
    "Extract the **mu** vectors (posterior means) in batches of 2048\n",
    "to avoid GPU OOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000015",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODE_BATCH = 2048\n",
    "\n",
    "encode_loader = DataLoader(\n",
    "    TensorDataset(tensor_X),\n",
    "    batch_size=ENCODE_BATCH,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "latent_parts: list[np.ndarray] = []\n",
    "module.eval()  # use unwrapped module for encoding (single-device, deterministic)\n",
    "with torch.no_grad():\n",
    "    for (batch,) in tqdm(encode_loader, desc=\"Encoding latent codes\"):\n",
    "        mu, _ = module.encode(batch)\n",
    "        latent_parts.append(mu.cpu().numpy())\n",
    "\n",
    "Z = np.concatenate(latent_parts, axis=0)\n",
    "print(f\"Latent codes: {Z.shape}  (samples x latent_dim)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000016",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Latent-Feature Pearson Correlation\n",
    "\n",
    "For each latent dimension $z_i$, compute the Pearson correlation\n",
    "with every observable feature.  Since Pearson $r$ is invariant to\n",
    "affine transformations, correlations are identical whether computed\n",
    "on raw or z-scored features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000017",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent = Z.shape[1]\n",
    "n_features = len(feature_names)\n",
    "\n",
    "corr_matrix = np.empty((n_latent, n_features), dtype=np.float64)\n",
    "pval_matrix = np.empty((n_latent, n_features), dtype=np.float64)\n",
    "\n",
    "for zi in tqdm(range(n_latent), desc=\"Computing correlations\"):\n",
    "    z_col = Z[:, zi]\n",
    "    for fi in range(n_features):\n",
    "        r, p = pearsonr(z_col, X[:, fi])\n",
    "        corr_matrix[zi, fi] = r\n",
    "        pval_matrix[zi, fi] = p\n",
    "\n",
    "print(f\"Correlation matrix: {corr_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of full correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(max(14, n_features * 0.35), max(4, n_latent * 0.6)))\n",
    "im = ax.imshow(corr_matrix, cmap=\"RdBu_r\", vmin=-1, vmax=1, aspect=\"auto\")\n",
    "\n",
    "ax.set_yticks(range(n_latent))\n",
    "ax.set_yticklabels([f\"z{i}\" for i in range(n_latent)])\n",
    "ax.set_xticks(range(n_features))\n",
    "ax.set_xticklabels(feature_names, rotation=90, fontsize=6)\n",
    "ax.set_title(\"Pearson Correlation: Latent Dimensions vs Features\")\n",
    "fig.colorbar(im, ax=ax, label=\"Pearson r\", shrink=0.8)\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"vae_correlation_heatmap.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000019",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Interpretation Table (Top-5 Features per Latent Dimension)\n",
    "\n",
    "For each $z_i$, rank features by absolute Pearson $|r|$ and report\n",
    "the five strongest correlates with direction and significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000020",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "\n",
    "table_rows: list[dict[str, object]] = []\n",
    "for zi in range(n_latent):\n",
    "    abs_corr = np.abs(corr_matrix[zi])\n",
    "    top_idx = np.argsort(abs_corr)[::-1][:TOP_K]\n",
    "    for rank, fi in enumerate(top_idx, start=1):\n",
    "        table_rows.append({\n",
    "            \"latent_dim\": f\"z{zi}\",\n",
    "            \"rank\": rank,\n",
    "            \"feature\": feature_names[fi],\n",
    "            \"pearson_r\": round(float(corr_matrix[zi, fi]), 4),\n",
    "            \"abs_r\": round(float(abs_corr[fi]), 4),\n",
    "            \"p_value\": float(pval_matrix[zi, fi]),\n",
    "        })\n",
    "\n",
    "df_interp = pl.DataFrame(table_rows)\n",
    "print(df_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compact pivot view: one row per latent dim, columns = rank\n",
    "pivot_rows: list[dict[str, object]] = []\n",
    "for zi in range(n_latent):\n",
    "    dim_df = df_interp.filter(pl.col(\"latent_dim\") == f\"z{zi}\").sort(\"rank\")\n",
    "    row: dict[str, object] = {\"dim\": f\"z{zi}\"}\n",
    "    for rank_i in range(TOP_K):\n",
    "        feat = dim_df[\"feature\"][rank_i]\n",
    "        r_val = dim_df[\"pearson_r\"][rank_i]\n",
    "        row[f\"#{rank_i + 1}\"] = f\"{feat} ({r_val:+.3f})\"\n",
    "    pivot_rows.append(row)\n",
    "\n",
    "df_pivot = pl.DataFrame(pivot_rows)\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "df_interp.write_parquet(OUTPUT_DIR / \"latent_interpretation.parquet\")\n",
    "df_pivot.write_csv(OUTPUT_DIR / \"latent_interpretation_pivot.csv\")\n",
    "print(f\"Saved interpretation tables to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: top-5 absolute correlations per latent dim\n",
    "fig, axes = plt.subplots(\n",
    "    2, (n_latent + 1) // 2,\n",
    "    figsize=(4 * ((n_latent + 1) // 2), 7),\n",
    "    sharey=False,\n",
    ")\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for zi in range(n_latent):\n",
    "    ax = axes_flat[zi]\n",
    "    dim_df = df_interp.filter(pl.col(\"latent_dim\") == f\"z{zi}\").sort(\"rank\")\n",
    "    features_top = dim_df[\"feature\"].to_list()\n",
    "    r_vals = dim_df[\"pearson_r\"].to_list()\n",
    "    colors = [\"#c44e52\" if r < 0 else \"#4c72b0\" for r in r_vals]\n",
    "    ax.barh(range(TOP_K - 1, -1, -1), r_vals, color=colors)\n",
    "    ax.set_yticks(range(TOP_K - 1, -1, -1))\n",
    "    ax.set_yticklabels(features_top, fontsize=7)\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.axvline(0, color=\"black\", linewidth=0.5)\n",
    "    ax.set_title(f\"z{zi}\", fontsize=10)\n",
    "    ax.set_xlabel(\"Pearson r\", fontsize=8)\n",
    "\n",
    "# Hide unused axes\n",
    "for i in range(n_latent, len(axes_flat)):\n",
    "    axes_flat[i].set_visible(False)\n",
    "\n",
    "fig.suptitle(\"Top-5 Feature Correlates per Latent Dimension\", fontsize=13, y=1.01)\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"vae_top5_correlations.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000024",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Latent Space UMAP Visualisation\n",
    "\n",
    "Project the 8-D latent codes to 2-D with UMAP, colouring points\n",
    "by the feature most correlated with each sample's dominant latent\n",
    "dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000025",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_components=2, random_state=cfg.random_state, n_jobs=-1)\n",
    "Z_2d = umap_model.fit_transform(Z)\n",
    "print(f\"UMAP embedding: {Z_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour by the latent dimension with highest absolute activation\n",
    "dominant_dim = np.argmax(np.abs(Z), axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "scatter = ax.scatter(\n",
    "    Z_2d[:, 0], Z_2d[:, 1],\n",
    "    c=dominant_dim,\n",
    "    cmap=\"tab10\",\n",
    "    s=4,\n",
    "    alpha=0.5,\n",
    "    rasterized=True,\n",
    ")\n",
    "cbar = fig.colorbar(scatter, ax=ax, label=\"Dominant Latent Dim\")\n",
    "cbar.set_ticks(range(n_latent))\n",
    "cbar.set_ticklabels([f\"z{i}\" for i in range(n_latent)])\n",
    "ax.set_title(\"UMAP of VAE Latent Space (coloured by dominant dimension)\")\n",
    "ax.set_xlabel(\"UMAP-1\")\n",
    "ax.set_ylabel(\"UMAP-2\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"vae_umap_latent.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-dimension activation maps\n",
    "fig, axes = plt.subplots(\n",
    "    2, (n_latent + 1) // 2,\n",
    "    figsize=(4 * ((n_latent + 1) // 2), 7),\n",
    ")\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for zi in range(n_latent):\n",
    "    ax = axes_flat[zi]\n",
    "    sc = ax.scatter(\n",
    "        Z_2d[:, 0], Z_2d[:, 1],\n",
    "        c=Z[:, zi],\n",
    "        cmap=\"coolwarm\",\n",
    "        s=2,\n",
    "        alpha=0.4,\n",
    "        rasterized=True,\n",
    "    )\n",
    "    ax.set_title(f\"z{zi}\", fontsize=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.colorbar(sc, ax=ax, shrink=0.7)\n",
    "\n",
    "for i in range(n_latent, len(axes_flat)):\n",
    "    axes_flat[i].set_visible(False)\n",
    "\n",
    "fig.suptitle(\"UMAP coloured by individual latent activations\", fontsize=13, y=1.01)\n",
    "fig.tight_layout()\n",
    "fig.savefig(OUTPUT_DIR / \"vae_umap_per_dim.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000028",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained VAE state dict + config for downstream use\n",
    "model_path = OUTPUT_DIR / \"vae_model.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": module.state_dict(),\n",
    "        \"input_dim\": input_dim,\n",
    "        \"config_latent_dim\": cfg.latent_dim,\n",
    "        \"config_hidden_dims\": cfg.hidden_dims,\n",
    "        \"config_beta\": cfg.beta,\n",
    "        \"config_learning_rate\": cfg.learning_rate,\n",
    "        \"config_batch_size\": cfg.batch_size,\n",
    "        \"config_n_epochs\": cfg.n_epochs,\n",
    "        \"config_dropout\": cfg.dropout,\n",
    "        \"config_random_state\": cfg.random_state,\n",
    "        \"training_losses\": epoch_losses,\n",
    "    },\n",
    "    model_path,\n",
    ")\n",
    "\n",
    "# Save latent codes for hybrid GMM/HMM experiments\n",
    "np.save(OUTPUT_DIR / \"latent_codes.npy\", Z)\n",
    "\n",
    "# Save preprocessing pipeline\n",
    "pipeline.save(OUTPUT_DIR / \"preprocessing_pipeline.pkl\")\n",
    "\n",
    "# Save correlation matrix\n",
    "np.savez(\n",
    "    OUTPUT_DIR / \"correlation_matrix.npz\",\n",
    "    corr=corr_matrix,\n",
    "    pval=pval_matrix,\n",
    "    feature_names=np.array(feature_names),\n",
    ")\n",
    "\n",
    "print(f\"All artifacts saved to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0000030",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary & Next Steps\n",
    "\n",
    "**Produced:**\n",
    "- Trained beta-VAE (8-D latent space) on combined dataset\n",
    "- Latent dimension interpretation table (top-5 correlated features per dim)\n",
    "- UMAP visualisation of latent space structure\n",
    "- Saved latent codes for downstream hybrid analysis (GMM on latent codes)\n",
    "\n",
    "**Next steps (Task 5.5):**\n",
    "- Fit GMM on VAE latent codes and compare to direct-feature GMM\n",
    "- Compare state agreement, BIC, and silhouette between the two approaches\n",
    "- Evaluate whether the VAE latent space yields more interpretable states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
